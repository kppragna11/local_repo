{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, HuberRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\Student\\Desktop\\1ga21ec096\\local_repo\\silkboard.csv'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Handle non-numeric values\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Impute missing values with the most frequent value\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Calculate z-scores for each column\n",
    "z_scores = np.abs((df_imputed - df_imputed.mean()) / df_imputed.std())\n",
    "\n",
    "# Remove rows with z-scores beyond a certain threshold (e.g., 3)\n",
    "df_no_outliers = df_imputed[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# Select features and target variable\n",
    "X = df_no_outliers.drop(\"PM2.5\", axis=1)\n",
    "y = df_no_outliers[\"PM2.5\"]\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dictionary of base regression models with parallelization for RandomForest and GradientBoosting\n",
    "linear_reg = LinearRegression()\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "elastic_net_reg = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "huber_reg = HuberRegressor(epsilon=1.2)\n",
    "svr_reg = SVR(kernel='linear', C=1.0)\n",
    "gb_reg = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "dt_reg = DecisionTreeRegressor(max_depth=10)\n",
    "\n",
    "# Dictionary of base models\n",
    "models = {\n",
    "    'Linear Regression': linear_reg,\n",
    "    'Lasso Regression': lasso_reg,\n",
    "    'Ridge Regression': ridge_reg,\n",
    "    'Elastic Net Regression': elastic_net_reg,\n",
    "    'Huber Regression': huber_reg,\n",
    "    'SVR': svr_reg,\n",
    "    'Gradient Boosting': gb_reg,\n",
    "    'KNN': knn_reg,\n",
    "    'Decision Tree': dt_reg\n",
    "}\n",
    "\n",
    "# Create a Stacking Regressor with a placeholder final_estimator\n",
    "stacked_reg = StackingRegressor(\n",
    "    estimators=list(models.items()),\n",
    "    final_estimator=None\n",
    ")\n",
    "\n",
    "# Dictionary to store cross-validation results\n",
    "cv_results = {}\n",
    "\n",
    "# Perform cross-validation for each base model\n",
    "for name, model in models.items():\n",
    "    cv_score = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_results[name] = np.sqrt(-cv_score)\n",
    "\n",
    "# Display cross-validation results\n",
    "print(\"Cross-Validation Results:\")\n",
    "for name, scores in cv_results.items():\n",
    "    print(f\"{name}: Mean RMSE = {np.mean(scores)}, Std Dev = {np.std(scores)}\")\n",
    "\n",
    "# Modify the potential_final_estimators dictionary\n",
    "potential_final_estimators = {\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'param_dist': {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingRegressor(),\n",
    "        'param_dist': {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2]\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'param_dist': {\n",
    "            'n_neighbors': [3, 5, 7],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'param_dist': {\n",
    "            'max_depth': [5, 10, 15],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Modify the final_estimator_param_dist dictionary\n",
    "final_estimator_param_dist = {\n",
    "    'final_estimator': list(potential_final_estimators.values())\n",
    "}\n",
    "\n",
    "# Perform a randomized search for the stacking regressor with parallelization\n",
    "randomized_search = RandomizedSearchCV(\n",
    "    stacked_reg,\n",
    "    param_distributions=final_estimator_param_dist,\n",
    "    n_iter=len(potential_final_estimators),  # Use the total number of final estimator models\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'\n",
    ")\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best final estimator\n",
    "best_final_estimator_config = randomized_search.best_params_['final_estimator']\n",
    "\n",
    "# Use the best final estimator in the stacking regressor\n",
    "stacked_reg.final_estimator = best_final_estimator_config['model']\n",
    "\n",
    "# Define hyperparameter distributions for the stacking regressor\n",
    "param_dist = {\n",
    "    'final_estimator__max_depth': [3, 5, 7],\n",
    "    'final_estimator__n_estimators': [50, 100, 150],\n",
    "    'linear__fit_intercept': [True, False],\n",
    "    'lasso__alpha': [0.01, 0.1, 1.0],\n",
    "    'ridge__alpha': [0.01, 0.1, 1.0],\n",
    "    'elastic_net__alpha': [0.01, 0.1, 1.0],\n",
    "    'elastic_net__l1_ratio': [0.1, 0.5, 0.9],\n",
    "    'huber__epsilon': [1.1, 1.2, 1.3],\n",
    "    'svr__C': [0.1, 1, 10],\n",
    "    'gradientboosting__n_estimators': [50, 100, 150],\n",
    "    'gradientboosting__max_depth': [3, 5, 7],\n",
    "    'knn__n_neighbors': [3, 5, 7],\n",
    "    'decisiontree__max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Perform randomized search for the stacking regressor with parallelization\n",
    "randomized_search_stacked = RandomizedSearchCV(\n",
    "    stacked_reg,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "randomized_search_stacked.fit(X_train, y_train)\n",
    "\n",
    "# Get the best stacking regressor\n",
    "best_stacked_model = randomized_search_stacked.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_stacked = best_stacked_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the best stacking regressor\n",
    "mse_stacked = mean_squared_error(y_test, y_pred_stacked)\n",
    "rmse_stacked = np.sqrt(mse_stacked)\n",
    "r2_stacked = r2_score(y_test, y_pred_stacked)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Performance Metrics for Each Model:\")\n",
    "for name, scores in cv_results.items():\n",
    "    print(f\"{name} - Mean RMSE: {np.mean(scores)}, Std Dev: {np.std(scores)}\")\n",
    "\n",
    "print(\"\\nBest Stacked Model:\")\n",
    "print(f\"Stacked Regressor - MSE: {mse_stacked}, RMSE: {rmse_stacked}, R-squared: {r2_stacked}\")\n",
    "\n",
    "# Plot actual vs. predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_stacked, alpha=0.5)\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
