{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, HuberRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>WS</th>\n",
       "      <th>WD</th>\n",
       "      <th>BP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.25</td>\n",
       "      <td>70.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>31.52</td>\n",
       "      <td>17.35</td>\n",
       "      <td>17.88</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.33</td>\n",
       "      <td>44.08</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>27.10</td>\n",
       "      <td>89.00</td>\n",
       "      <td>1.63</td>\n",
       "      <td>76.75</td>\n",
       "      <td>713.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>32.20</td>\n",
       "      <td>17.50</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.72</td>\n",
       "      <td>0.32</td>\n",
       "      <td>44.24</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>27.08</td>\n",
       "      <td>90.00</td>\n",
       "      <td>1.68</td>\n",
       "      <td>76.75</td>\n",
       "      <td>712.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.00</td>\n",
       "      <td>79.50</td>\n",
       "      <td>0.47</td>\n",
       "      <td>29.63</td>\n",
       "      <td>16.10</td>\n",
       "      <td>18.07</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.35</td>\n",
       "      <td>44.02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>24.90</td>\n",
       "      <td>89.75</td>\n",
       "      <td>1.62</td>\n",
       "      <td>79.50</td>\n",
       "      <td>712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.00</td>\n",
       "      <td>81.25</td>\n",
       "      <td>0.53</td>\n",
       "      <td>23.22</td>\n",
       "      <td>12.75</td>\n",
       "      <td>16.60</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.32</td>\n",
       "      <td>42.34</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>21.67</td>\n",
       "      <td>90.75</td>\n",
       "      <td>1.88</td>\n",
       "      <td>80.00</td>\n",
       "      <td>712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.50</td>\n",
       "      <td>72.75</td>\n",
       "      <td>0.90</td>\n",
       "      <td>22.93</td>\n",
       "      <td>12.93</td>\n",
       "      <td>16.30</td>\n",
       "      <td>4.23</td>\n",
       "      <td>0.42</td>\n",
       "      <td>41.54</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.98</td>\n",
       "      <td>87.75</td>\n",
       "      <td>1.57</td>\n",
       "      <td>85.00</td>\n",
       "      <td>712.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PM2.5   PM10    NO    NO2    NOx    NH3   SO2    CO  Ozone  Benzene  \\\n",
       "0  48.25  70.50  0.70  31.52  17.35  17.88  5.20  0.33  44.08      0.2   \n",
       "1  55.00  78.00  0.42  32.20  17.50  17.95  5.72  0.32  44.24      0.2   \n",
       "2  57.00  79.50  0.47  29.63  16.10  18.07  4.43  0.35  44.02      0.2   \n",
       "3  61.00  81.25  0.53  23.22  12.75  16.60  3.65  0.32  42.34      0.2   \n",
       "4  55.50  72.75  0.90  22.93  12.93  16.30  4.23  0.42  41.54      0.2   \n",
       "\n",
       "   Toluene   Temp     RH    WS     WD     BP  \n",
       "0     0.40  27.10  89.00  1.63  76.75  713.0  \n",
       "1     0.38  27.08  90.00  1.68  76.75  712.5  \n",
       "2     0.43  24.90  89.75  1.62  79.50  712.0  \n",
       "3     0.40  21.67  90.75  1.88  80.00  712.0  \n",
       "4     0.42  21.98  87.75  1.57  85.00  712.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path=(r'C:\\Users\\Student\\Desktop\\1ga21ec096\\local_repo\\silkboard.csv')\n",
    "df = pd.read_csv(file_path,low_memory=False)\n",
    "\n",
    "# Handle non-numeric values\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Impute missing values with the most frequent value\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "# Display the first few rows of the dataset\n",
    "columns = ['PM10', 'NO', 'NO2', 'NOx', 'NH3', 'SO2', 'CO', 'Ozone', 'Benzene', 'Toluene', 'Temp', 'RH', 'WS', 'WD', 'BP']\n",
    "df_imputed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X (features) and y (target variable)\n",
    "X = df_imputed[columns]\n",
    "y = df_imputed['PM2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for models\n",
    "params_xgb = {'lambda': 0.7044156083795233, 'alpha': 9.681476940192473, 'colsample_bytree': 0.3, 'subsample': 0.8,\n",
    "              'learning_rate': 0.015, 'max_depth': 3, 'min_child_weight': 235, 'random_state': 48, 'n_estimators': 30000}\n",
    "\n",
    "params_lgb = {'reg_alpha': 4.973064761998367, 'reg_lambda': 0.06365096912006087, 'colsample_bytree': 0.24,\n",
    "              'subsample': 0.8, 'learning_rate': 0.015, 'max_depth': 100, 'num_leaves': 43, 'min_child_samples': 141,\n",
    "              'cat_smooth': 18, 'metric': 'rmse', 'random_state': 48, 'n_estimators': 40000}\n",
    "\n",
    "params_rf= {\n",
    "            'n_estimators': 800,\n",
    "            'max_depth': 5,\n",
    "            'min_samples_split': 3,\n",
    "            'min_samples_leaf': 2}\n",
    "params_gb={\n",
    "       \n",
    "            'n_estimators': 800,\n",
    "            'max_depth': 5,\n",
    "            'learning_rate': 0.01}\n",
    "params_knn={'n_neighbors': 3}\n",
    "params_dt= {\n",
    "       \n",
    "            'max_depth': 5, \n",
    "            'min_samples_split': 5,\n",
    "            'min_samples_leaf': 2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays for predictions\n",
    "pred1 = np.zeros(df_imputed.shape[0])\n",
    "pred2 = np.zeros(df_imputed.shape[0])\n",
    "pred3 = np.zeros(df_imputed.shape[0])\n",
    "pred4 = np.zeros(df_imputed.shape[0])\n",
    "pred5 = np.zeros(df_imputed.shape[0])\n",
    "pred6 = np.zeros(df_imputed.shape[0])\n",
    "pred7 = np.zeros(df_imputed.shape[0])\n",
    "pred8 = np.zeros(df_imputed.shape[0])\n",
    "pred9 = np.zeros(df_imputed.shape[0])\n",
    "pred10 = np.zeros(df_imputed.shape[0])\n",
    "pred11= np.zeros(df_imputed.shape[0])\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=48, shuffle=True)\n",
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3352\n",
      "[LightGBM] [Info] Number of data points in the train set: 41861, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 23.331016\n",
      "fold: 2\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3353\n",
      "[LightGBM] [Info] Number of data points in the train set: 41861, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 23.326325\n",
      "fold: 3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3350\n",
      "[LightGBM] [Info] Number of data points in the train set: 41862, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 23.299920\n",
      "fold: 4\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3350\n",
      "[LightGBM] [Info] Number of data points in the train set: 41862, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 23.305952\n",
      "fold: 5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3349\n",
      "[LightGBM] [Info] Number of data points in the train set: 41862, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 23.278913\n"
     ]
    }
   ],
   "source": [
    "for trn_idx, test_idx in kf.split(X, y):\n",
    "    print(f\"fold: {n+1}\")\n",
    "    X_tr, X_val = X.iloc[trn_idx], X.iloc[test_idx]\n",
    "    y_tr, y_val = y.iloc[trn_idx], y.iloc[test_idx]\n",
    "        # Model 1: LGBMRegressor\n",
    "    model1 = lgb.LGBMRegressor(**params_lgb)\n",
    "    model1.fit(X_tr, y_tr)  # Remove the early_stopping_rounds parameter\n",
    "    pred1[test_idx] = model1.predict(X_val)\n",
    " \n",
    "    # Model 2: ElasticNet\n",
    "    model2 = ElasticNet(alpha=0.00001, max_iter=10000)\n",
    "\n",
    "    model2.fit(X_tr, y_tr)\n",
    "    pred2[test_idx] = model2.predict(X_val)\n",
    "\n",
    "    # Model 3: LinearRegression\n",
    "    model3 = LinearRegression()\n",
    "    model3.fit(X_tr, y_tr)\n",
    "    pred3[test_idx] = model3.predict(X_val)\n",
    "\n",
    "    # Model 4: XGBRegressor\n",
    "    model4 = xgb.XGBRegressor(**params_xgb)\n",
    "    model4.set_params(early_stopping_rounds=200)  # You can set other parameters if needed\n",
    "    model4.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    pred4[test_idx] = model4.predict(X_val)\n",
    "\n",
    "    model5 = Ridge(alpha=1.0)\n",
    "    model5.fit(X_tr, y_tr)\n",
    "    pred5[test_idx] = model5.predict(X_val)\n",
    "    \n",
    "    model6= RandomForestRegressor(**params_rf)\n",
    "    model6.fit(X_tr, y_tr)\n",
    "    pred6[test_idx] = model6.predict(X_val)\n",
    "    \n",
    "    model7= HuberRegressor(epsilon=1.2,max_iter=1000)\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    model7 = make_pipeline(scaler, model7)\n",
    "    model7.fit(X_tr, y_tr)\n",
    "    pred7[test_idx] = model7.predict(X_val)\n",
    "    \n",
    "    \n",
    "    model9 = GradientBoostingRegressor(**params_gb)\n",
    "    model9.fit(X_tr, y_tr)\n",
    "    pred9[test_idx] = model9.predict(X_val)\n",
    "    \n",
    "    model10 = KNeighborsRegressor(**params_knn)\n",
    "    model10.fit(X_tr, y_tr)\n",
    "    pred10[test_idx] = model10.predict(X_val)\n",
    "    \n",
    "    model11= DecisionTreeRegressor(**params_dt)\n",
    "    model11.fit(X_tr, y_tr)\n",
    "    pred11[test_idx] = model11.predict(X_val)\n",
    "\n",
    "    n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Stack the predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m stacked_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mcolumn_stack((pred1, pred2, pred3, pred4,pred5, pred6, pred7,pred9, pred10, pred11))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Define the meta-model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m kf1\u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Stack the predictions\n",
    "stacked_predictions = np.column_stack((pred1, pred2, pred3, pred4,pred5, pred6, pred7,pred9, pred10, pred11))\n",
    "# Define the meta-model\n",
    "kf1= KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "\n",
    "# Create LassoCV model with a range of alpha values\n",
    "alphas = np.logspace(-6, 6, 13)  # Adjust the range based on your specific needs\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=kf1)\n",
    "\n",
    "# Fit the LassoCV model\n",
    "lasso_cv.fit(X, y)\n",
    "\n",
    "# Get the optimal alpha\n",
    "optimal_alpha = lasso_cv.alpha_\n",
    "print(f'Optimal Alpha: {optimal_alpha}')\n",
    "\n",
    "# Fit the final Lasso model with the optimal alpha\n",
    "meta_model= Lasso(alpha=optimal_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.743e+06, tolerance: 1.752e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Train the meta-model on stacked predictions\n",
    "meta_model.fit(stacked_predictions, y)\n",
    "# Prepare test data\n",
    "test_data = df_imputed[columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using base models\n",
    "pred1_test = model1.predict(test_data)\n",
    "pred2_test = model2.predict(test_data)\n",
    "pred3_test = model3.predict(test_data)\n",
    "pred4_test = model4.predict(test_data)\n",
    "pred5_test = model5.predict(test_data)\n",
    "pred6_test = model6.predict(test_data)\n",
    "pred7_test = model7.predict(test_data)\n",
    "\n",
    "pred9_test = model9.predict(test_data)\n",
    "pred10_test = model10.predict(test_data)\n",
    "pred11_test = model11.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the predictions\n",
    "stacked_predictions_test = np.column_stack((pred1_test, pred2_test, pred3_test, pred4_test,pred5_test,pred6_test,pred7_test,pred9_test,pred10_test,pred11_test))\n",
    "\n",
    "# Use the meta-model to make final predictions\n",
    "final_predictions_test = meta_model.predict(stacked_predictions_test)\n",
    "y_test=df_imputed['PM2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[1;32m----> 2\u001b[0m final_rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(\u001b[43my_test\u001b[49m, final_predictions_test, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m mse_stacked \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, final_predictions_test)\n\u001b[0;32m      4\u001b[0m rmse_stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mse_stacked)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "final_rmse = mean_squared_error(y_test, final_predictions_test, squared=False)\n",
    "mse_stacked = mean_squared_error(y_test, final_predictions_test)\n",
    "rmse_stacked = np.sqrt(mse_stacked)\n",
    "r2_stacked = r2_score(y_test, final_predictions_test)\n",
    "print(f\"Final RMSE on the test set: {final_rmse}\")\n",
    "print(f\"Final RMSE_STACK on the test set: {rmse_stacked}\")\n",
    "print(f\"Final MSE on the test set: {mse_stacked}\")\n",
    "print(f\"Final r2 on the test set: {r2_stacked}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
